import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from xgboost import XGBClassifier

# ===============================
# 1Ô∏è‚É£ Load Optimized Data
# ===============================
df = pd.read_csv("XAUUSD_Features.csv")
print("‚úÖ Data loaded:", df.shape)

# Select only numeric columns (avoid 'time' or other strings)
X = df.select_dtypes(include=['float64', 'int64'])
y = df["Target"]

# Split train/test data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
print("üîπ Training data:", X_train.shape)
print("üîπ Testing data:", X_test.shape)

# ===============================
# 2Ô∏è‚É£ Scaling
# ===============================
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ===============================
# 3Ô∏è‚É£ Build Stacked Ensemble
# ===============================
base_models = [
    ('rf', RandomForestClassifier(n_estimators=100, max_depth=8, random_state=42)),
    ('xgb', XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42, use_label_encoder=False, eval_metric='logloss')),
    ('svm', SVC(kernel='rbf', probability=True, random_state=42))
]

stack_model = StackingClassifier(
    estimators=base_models,
    final_estimator=GradientBoostingClassifier(),
    n_jobs=-1
)

print("ü§ñ Training stacked ensemble model...")
stack_model.fit(X_train_scaled, y_train)
print("‚úÖ Stacking model training complete!")

# ===============================
# 4Ô∏è‚É£ Evaluation
# ===============================
y_pred = stack_model.predict(X_test_scaled)
acc = accuracy_score(y_test, y_pred)
cm = confusion_matrix(y_test, y_pred)

print(f"\nüéØ Ensemble Accuracy: {acc:.4f}")
print("\nüìã Classification Report:\n", classification_report(y_test, y_pred))
print("\nüìä Confusion Matrix:\n", cm)

# ===============================
# 5Ô∏è‚É£ Visualization
# ===============================
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title(f'Confusion Matrix (Accuracy={acc:.2f})')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# ===============================
# 6Ô∏è‚É£ Feature Importance (RandomForest)
# ===============================
rf = base_models[0][1]
rf.fit(X_train_scaled, y_train)
importance = pd.Series(rf.feature_importances_, index=X.columns)
importance = importance.sort_values(ascending=False)

plt.figure(figsize=(10,5))
sns.barplot(x=importance[:10], y=importance.index[:10], palette='viridis')
plt.title("Top 10 Important Features")
plt.xlabel("Importance Score")
plt.ylabel("Feature")
plt.show()

# ===============================
# 7Ô∏è‚É£ Save Models
# ===============================
joblib.dump(stack_model, "AI_Trading_Stacked_Model.pkl")
joblib.dump(scaler, "AI_Trading_Scaler.pkl")

print("\nüíæ Ensemble model and scaler saved successfully!")
